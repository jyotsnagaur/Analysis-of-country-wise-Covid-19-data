---
title: "FinalAssignment"
author: "JYOTSNA"
date: "2022-10-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part A - Data Science Questions (12 marks)


<b>Q1. From your understanding of ethical data science, mention three principles of a code of ethics that any data scientist should consider.</b>

P1:As a data scientist, we should firstly produce truthful results to the public/stakeholders. We must abstain from producing false projections or 'truthful falsehood'.Truthful falsehood is projecting data in a misleading manner which shows a misleading trend to the people.

P2:It is important to respect the privacy of the people/stakeholders and seek their consent before collecting or using their data for any kind of analysis.

P3:It is important to remember that we remain a member of the society and it is important to work in a manner that is progressive for the society at large. As a data scientist we must be careful to not publish sensitive data and have no intentions of causing harm to public health and safety.




<b>Q2.To build a visualisation using the ggplot2 library, we use the following template:</b>

ggplot(data= [dataset], mapping = aes(x = [x-variable], y = [y-variable]))+
geom_xxx() +
other options 
Based on the above template, mention the main components of building a graph using ggplot2 and describe the meaning of each of these components.


There are 3 main components here:

a) the dataset which needs to be displayed. It has to be contained in a data frame/tibble and has to include the x-variable which comes on the x-axis and which is the independent/explanatory variable. It has to also include the y-variable which is the dependent/response variable which changes as x changes and is plotted on the y-axis

b) aesthetics, introduced by the function aes() that takes care of positioning/mapping the variables on the plot.It also includes other elements like color where we can specify if the plot needs to be colored as per a specific group or a specific color. It can include specification for alpha which shows the transparency of plot. It can also contain specification for linetype, size,shape,etc.

c) geometry, introduced by the function geom() that takes care of drawing the graph (bar graph, line, scatter plot, etc). There can be different geometries like horizontal,vertical,diagonal lines, barplot,contour,density plots,point,boxplot,jitter,polygon etc.All of these geometries can be plotted using their respective codes starting with geom_.




<b>Q3.Describe three properties of the correlation coefficient of two variables</b>


1.  The Magnitude of the correlation coefficient(R) represents the strength of the relationship. It ranges between -1 and +1.

2.  Direction of the relationship: This is indicated by the sign of the correlation coefficient. A positive R represents an increasing trend in the graph where the y-variable increases with increase in x-variable. A negative R represents a decreasing trend where y-variable decreases with increase in x-variable.

3.  The correlation coefficient is unit-less. The value will stay very similar even with scaling or normalising any of the variables. The correlation coefficient between x and y is same as the correlation coefficient between y and x. 




<b>Q4.Imagine we have a dataset that lists the heights of the fathers and their sons. You have built a linear model that encodes the relationship between the fathers’ heights and the sons’ heights as follows:</b>

lm(son ~ father, data = heights_data)

Call:
lm(formula = son ~ father, data = heights_data)

Coefficients:
(Intercept)    father  
70.45       0.50  
The estimated coefficient (i.e. intercept and slope), which describes the relationship between the fathers’ and sons’ heights can be interpreted as:


a) The intercept is the minimum or maximum value that can be achieved when the explanatory variable equals 0. Here the explanatory variable is the father's height and the response variable is the son's height. The intercept 70.45 units here can be interpreted as the constant difference that the father's and son's height will have, apart from their linear relationship. At any given father's height, the son's height is bound to be atleast 70.45 units more than the height of the father. In simple words, all sons in the dataset are taller than their father.

b) The slope quantifies the effect of explanatory variable(father's height) on the response variable(son's height). Here the slope measures: for each unit increase in the father's height, how much would the height of the son would increase. Here since the slope is 0.5, it means that for each 2 units increase in the height of the father, the height of the son increases by 1 unit.


# --------------------------------------------------------------------------------- #

# Part B: Data Preparation, exploring and modelling (78 marks)


Data Description:
The four CSV files are described in the following table:
-Covid19.csv: Master file which includes information on continents,countries, and the daily new cases and the daily new deaths in each country
-Tests.csv:information about daily covid19 tests in each country
-Countries.csv:information about the countries
-Recovered.csv:information about the daily recovered cases in each country

## Task 1: Data Preparation and Wrangling: (21 marks)

### 1.Load and read the data from the CSV files and store them into dataframes named appropriately.

```{r}
# install.packages("rlang")
```

```{r}
# importing library tidyverse which contains all the other packages (dplyr, ggplot2, etc.) used here for data exploration and visualisation.
library(tidyverse)


master_data <- read_csv("C:/joy_R/IDS_Finalexam/data/Covid19.csv")
head(master_data) # checking to see if a tibble is created
tests_info <- read_csv("C:/joy_R/IDS_Finalexam/data/Tests.csv")
head(tests_info) # checking to see if a tibble is created
country_info <- read_csv("C:/joy_R/IDS_Finalexam/data/Countries.csv")
head(country_info) # checking to see if a tibble is created
recov_info <- read_csv("C:/joy_R/IDS_Finalexam/data/Recovered.csv")
head(recov_info) # checking to see if a tibble is created
```

```{r}
str(master_data) # checking the structure of tibble created
```


```{r}
str(tests_info)  # checking the structure of tibble created
```


```{r}
str(country_info)  # checking the structure of tibble created
```

```{r}
str(recov_info)  # checking the structure of tibble created
```


### 2.Tidy up the dataframe driven from the file “Recovered.csv” to be compatible with the dataframe driven from the file “Covid19.csv”, i.e., every observation should have a record of recovered patients in one country in a single day.

```{r}
new_recov <- t(recov_info)  # transposing the tibble created for recovered data
#head(new_recov)  # checking to see the transposed tibble
```


```{r}
class(new_recov)  # checking the class of the tibble created for recovered data
```

```{r}
new_recov2 <- as.data.frame(new_recov)  # converting array values to data frame for further operation
head(new_recov2)
```


```{r}
colnames(new_recov2) <- c(new_recov2[1, ]) # assigning new column headers to each data frame in the list
#new_recov2   # checking to see the result
new_recov3 <- new_recov2[-c(1), ] # removing the repeating row names
#new_recov3  # checking to see the result
new_recov3$date <- row.names(new_recov3) # adding Date as the last column

head(new_recov3)
```
pivot_longer() is a function in tidyverse library. It converts data to long format, increasing the number of rows and decreasing the number of columns. 
```{r}
new_recov4 <- pivot_longer(new_recov3, #converting data to long format using pivot_longer function
  cols = 1:185, names_to = "location", #specifying column range and making all countries come into a single location column
  values_to = "cases"                  #making all the values of recovered cases come under the cases column
)
head(new_recov4) #checking head to see the result
```


```{r}
recov_5 <- new_recov4 %>%
  group_by(location) %>%   # grouping and arranging data by location to arrange country data together
  arrange(location)
head(recov_5)   # checking head to see the result
```

```{r}
recov_6 <- recov_5 %>% select(location, everything()) #placing the location column in front of others
#recov_6
recov_6$date <- as.Date(recov_6$date, format = "%Y.%m.%d")  #converting date column from chr to date type
head(recov_6)
```


### 3. Change the column names in the dataframes were loaded from the following files accordingly.
covid19.csv-Code,Country,Continent,Date,NewCases,NewDeaths
Tests.csv-Code, Date, NewTests
Countries.csv-Code,Country,Population,GDP,GDPCapita
Recovered.csv-Country,Date,Recovered

```{r}

colnames(master_data) <- c("Code", "Country", "Continent", "Date", "NewCases", "NewDeaths") #changing names by using colnames 
colnames(tests_info) <- c("Code", "Date", "NewTests")                            #changing names by using colnames
colnames(country_info) <- c("Code", "Country", "Population", "GDP", "GDPCapita") #changing names by using colnames
colnames(recov_6) <- c("Country", "Date", "Recovered")                           #changing names by using colnames

head(master_data)  #checking head to see the result
head(tests_info)   #checking head to see the result
head(country_info) #checking head to see the result
head(recov_6)      #checking head to see the result
```
### 4. Ensure that all dates variables are of date data type and with the same format across the dataframes.
```{r}
class(master_data$Date)
class(tests_info$Date)
class(recov_6$Date) # date variable changed to Date type in question-2 above.
# country_info data tibble does not have a Date variable. Rest in all data tibbles, the date variable is of Date type.
```

### 5. Considering the master dataframe is the one loaded from the “Covid19.csv” file, add new 5 variables to it from the other files (Recovered.csv, Tests.csv, Countries.csv). The 5 new added variables should be named (“Recovered”, “NewTests”, “Population”, “GDP”, “GDPCapita”) accordingly.

```{r}
# merging Recovered variable from the recov_6 dataframe. It has to be merged by using Date and Country column
m1 <- merge(x = master_data, y = recov_6, all.x = TRUE, by = c("Date", "Country"))
m1 <- m1 %>%
  group_by(Country) %>%  # grouping and arranging by country to keep country data together
  arrange(Country)
head(m1)
```

```{r}
# merging NewTests variable from the tests_info dataframe. It has to be merged by using Date and Code column
m2 <- merge(x = m1, y = tests_info, all.x = TRUE, by = c("Date", "Code"))
m2 <- m2 %>%
  group_by(Country) %>%   # grouping and arranging by country to keep country data together
  arrange(Country)
head(m2)
```

```{r}
# merging Population,GDP,GDPCapita variable from the country_info dataframe. It has to be merged by using Country and Code column
master_df <- merge(x = m2, y = country_info, all.x = TRUE, by = c("Code", "Country"))
master_df <- master_df %>%
  group_by(Country) %>%  # grouping and arranging by country to keep country data together
  arrange(Country)
head(master_df)
```

### 6.Check for NAs in all dataframes and change them to Zero
```{r}
# Check for NAs in master data frame
# is.na(master_df)
# converting Recovered column to numeric in master data frame
master_df$Recovered <- as.numeric(master_df$Recovered)
# changing NA values to 0
master_df[is.na(master_df)] <- 0
head(master_df) # check the data frame
```


```{r}
# Check for NAs in tests_info tibble
tests_info %>%
  summarise_all(funs(sum(is.na(.)))) %>%
  gather() %>%
  filter(value > 0)

# There are no NA values in tests_info
```
```{r}
# Check for NAs in country_info tibble
country_info %>%
  summarise_all(funs(sum(is.na(.)))) %>%
  gather() %>%
  filter(value > 0)

# There are no NA values in country_info
```

```{r}
# Check for NAs in recov_6 data frame
recov_6 %>%
  summarise_all(funs(sum(is.na(.)))) %>%
  gather() %>%
  filter(value > 0)

# there are 185 rows with an NA value

# changing NA values to 0
recov_6[is.na(recov_6)] <- 0
head(recov_6) # check the data frame
```

### 7. Using existing “Date” variable; add month and week variables to the master dataframe. [Hint: you may use functions from lubridate package]

Lubridate is a package in tidyverse. It also expands the type of mathematical operations that can be performed with date-time objects. It introduces new time span classes as well like period,duration,interval,etc.
```{r}
# install.packages("lubridate")
library(lubridate)

master_df2 <- master_df %>% mutate(Month = month(Date)) #adding month column using lubridate
head(master_df2)
```

```{r}
master_df3 <- master_df2 %>% mutate(Week = week(Date)) #adding week column using lubridate
head(master_df3)
```

# ------------------------------------------------------------------------------------ #

## Task 2: Exploratory Data Analysis: (35 marks)

### 1. Add four new variables to the master dataframe (“CumCases”, “CumDeaths”, “CumRecovered”, “CumTests”). These variables should reflect the cumulative relevant data up to the date of the observation; i.e., CumCases for country “X” at Date “Y” should reflect the total number of cases in country “X” since the beginning of recording data till the date “Y”.

[Hint: first arrange by date and country, then for each new variable to be added you need to group by country and mutate the new column using the cumsum function]
```{r}
# cumulative sum function can be used here
# The master_df3 already has a date and country column which is arranged as per dates.
master_df4 <- master_df3 %>%
  group_by(Country) %>%
  mutate(CumCases = cumsum(NewCases), CumDeaths = cumsum(NewDeaths), CumRecovered = cumsum(Recovered), CumTests = cumsum(NewTests))
head(master_df4)
```

### 2.Add two new variables to the master dataframe (“Active”, “FatalityRate”). Active variable should reflect the infected cases that has not been closed yet (by either recovery or death), and it could be calculated from (CumCases – (CumDeaths + CumRecovered)). On the other hand, FatalityRate variable should reflect the percentages of death to the infected cases up to date and it could be calculated from (CumDeaths / CumCases).
```{r}
master_df5 <- master_df4 %>%
  group_by(Country) %>%
  mutate(Active = (CumCases - (CumDeaths + CumRecovered)), FatalityRate = (CumDeaths / CumCases)) #using mutate to add new columns
head(master_df5) #checking head to see the result
```

### 3. Add four new variables to the master dataframe (“Cases_1M_Pop”, “Deaths_1M_Pop”, “Recovered_1M_Pop”, “Tests_1M_Pop”) These variables should reflect the cumulative relevant rate per one million of the corresponding country population, (i.e Cases_1M_Pop for country “X” at Date “Y” should reflect the total number of new cases up to date “Y” per million people of country “X” population)

[Hint: Cases_1M_Pop = CumCases*(10^6) / Population)]
```{r}
master_df6 <- master_df5 %>%
  group_by(Country) %>%
  mutate(Cases_1M_Pop = CumCases * (10^6) / Population, Deaths_1M_Pop = CumDeaths * (10^6) / Population, Recovered_1M_Pop = CumRecovered * (10^6) / Population, Tests_1M_Pop = CumTests * (10^6) / Population) #using mutate to add new columns
head(master_df6)  #checking head to see the result
```

### 4.Find the day with the highest reported death toll across the world. Print the date and the death toll of that day.
```{r}
deaths_per_day <- master_df6 %>%
  group_by(Date) %>%
  summarise(death_toll = sum(NewDeaths)) #grouping by date and summarising death toll using sum of daily deaths

#using which.max to find the row with highest number in death toll column and then printing its date and value
highest_death_toll <- deaths_per_day[[which.max(deaths_per_day$death_toll), "death_toll"]] 
highest_death_toll
highest_death_date <- deaths_per_day[[which.max(deaths_per_day$death_toll), "Date"]]
highest_death_date
```

### 5.Build a graph to show how the cumulative data of (Infected Cases, Deaths, Recovered, Tests) change over the time for the whole world collectively.

[Hint: Use geom_line as a geometry function, use log for the Y axis for better presentation, Use different colour to distinguish between new cases, deaths, and recovered]

```{r}

# Using summarise function to take sum of daily cases of different countries on each date
master_df7 <- master_df6 %>%
  group_by(Date) %>%
  summarise(Cases_world = sum(NewCases), Deaths_world = sum(NewDeaths), Recovered_world = sum(Recovered), Tests_world = sum(NewTests))


# to get the cumulative data of the above world variables I use cumsum function
master_df7$Cases_world <- cumsum(master_df7$Cases_world)
master_df7$Deaths_world <- cumsum(master_df7$Deaths_world)
master_df7$Recovered_world <- cumsum(master_df7$Recovered_world)
master_df7$Tests_world <- cumsum(master_df7$Tests_world)

master_df7 #checking data frame
```

```{r}
# plotting
library(ggplot2)
p <- ggplot(master_df7, aes(x = Date)) +
  geom_line(aes(y = Cases_world), colour = "green") +
  geom_line(aes(y = Deaths_world), colour = "red") +
  geom_line(aes(y = Recovered_world), colour = "blue") +
  geom_line(aes(y = Tests_world), colour = "grey") +
  xlab("Date") +
  ylab("Exponential values of cum cases, deaths,recovered, tests") +
  ggtitle("Trend of cumulative new cases, deaths,recovered and tests during Jan 2020 to May 2020 in the world")

# Possible values for trans : 'log2', 'log10'

# Format y axis tick mark labels to show exponents
require(scales)
p + scale_y_continuous(
  trans = log10_trans(),
  breaks = trans_breaks("log10", function(x) 10^x),
  labels = trans_format("log10", math_format(10^.x))
)
```


### 6.Extract the data corresonding to the last day (05/05/2020) and save it in a separate dataframe and name it “lastDay_data”.

[Hint: use filter function with Date = “2020-05-05”]

```{r}
lastDay_data <- master_df6 %>% filter(Date == "2020-05-05") #filtering a/c to date to get last day data
lastDay_data
```

### 7.Based on the data of the last day, extract the records of the top 10 countries worldwide that have current active cases, total confirmed cases, and fatality rate in separate dataframes (i.e., top10activeW, top10casesW, top10fatalityW, top10testsMW).

[Hint: you can use head(arranged_data, n=10) to get the top 10 records]
Firstly the data needs to be arranged according to the top 10 value of those columns selected. Then the first 10 rows are selected using the head function with n=10.
```{r}
top10activeW <- head(arrange(lastDay_data, desc(Active)), n = 10)
top10activeW
```

```{r}
top10casesW <- head(arrange(lastDay_data, desc(CumCases)), n = 10)
top10casesW
```

```{r}
top10fatalityW <- head(arrange(lastDay_data, desc(FatalityRate)), n = 10)
top10fatalityW
```


```{r}
top10testsMW <- head(arrange(lastDay_data, desc(Tests_1M_Pop)), n = 10)
top10testsMW
```

### 8.Based on the data of the last day, print the up to date confirmed, death, recovered cases as well as the tests for every continent
Firstly the data needs to be grouped by continent and then the new columns are obtained by summarising the values. Here I am taking the sum of each of the columns to print the latest sum of all cumulative cases 
```{r}
continent_data <- lastDay_data %>%
  group_by(Continent) %>%   #grouping the rows a/c to continent
  summarise(case_con = sum(CumCases), death_con = sum(CumDeaths), recov_con = sum(CumRecovered), test_con = sum(CumTests)) #taking the sum of CumCases from each country to represent the total cases values of that particular continent

continent_data
```


### 9. Build a graph to show the total number of cases over the time for the top 10 countries that have been obtained in question 7 (Use log for Y axis for better presentation).

[Hint: first you need to get the data of the top-10 countries and then plot their lines]


```{r}
# preparing data to plot

coun <- top10casesW$Code  #creating vector with Code names of top 10 countries with total cases

CumCases_with_time <- master_df6 %>% filter(Code %in% coun) #filtering a/c to code vector created above 

head(CumCases_with_time) #checking the result
```


```{r}

# plotting
library(ggplot2)
p <- ggplot(CumCases_with_time, aes(x = Date)) +
  geom_line(aes(y = CumCases, color = Country)) +
  xlab("Date") +
  ylab("Exponential values of total cases") +
  ggtitle("Total number of cases over the time for the top 10 countries")

# Possible values for trans : 'log2', 'log10'

# Format y axis tick mark labels to show exponents
require(scales)
p + scale_y_continuous(
  trans = log10_trans(),
  breaks = trans_breaks("log10", function(x) 10^x),
  labels = trans_format("log10", math_format(10^.x))
)
```

### 10. Build a graph for the top 10 countries with current highest active cases which was obtained previously in question 7. The graph should have one subgraph (i.e., using facet function) for each of these countries, every subgraph should show how the new cases, new deaths, and new recovered cases were changing over the time (Use log for Y axis for better presentation, Use different colour to distinguish between new cases, deaths, and recovered).

[hint: geom_line function with date on x_axis and each of the values of the variables in y_axis]

```{r}
# preparing data to plot

coun2 <- top10activeW$Code   #creating vector with Code names of top 10 countries with active cases

Active_with_time <- master_df6 %>% filter(Code %in% coun2) #filtering a/c to code vector created above

head(Active_with_time)  #checking the result
```



```{r fig.align="center", echo = FALSE,fig.width = 15}
# plotting
p <- ggplot(data = Active_with_time, aes(x = Date, color = y)) +
  geom_line(aes(y = NewCases, color = "New Cases")) +
  geom_line(aes(y = NewDeaths, color = "New Deaths")) +
  geom_line(aes(y = Recovered, color = "Recovered")) +
  xlab("Month") +
  ylab("Exponential values of total cases") +
  ggtitle("Daily new cases,recovered cases and deaths in top 10 countries with current highest active cases")



# facet wrap for subgraph according to country
q <- p + facet_wrap(~Country) + labs(color = "Daily New Cases")

# Possible values for trans : 'log2', 'log10'

# Format y axis tick mark labels to show exponents
require(scales)
q + scale_y_continuous(
  trans = log10_trans(),
  breaks = trans_breaks("log10", function(x) 10^x),
  labels = trans_format("log10", math_format(10^.x))
)
```

### 11. Build a graph for the top 10 countries with current highest total tests per one million of the population which was obtained previously in question 7. This graph should present total number of infected cases, total tests so far, and the total tests per million of the population for each country.

[hint: you can use bar chart to achieve this task]


```{r}
# Preparing the data
coun3 <- top10testsMW$Code  #creating vector with Code names of top 10 countries with tests per million

Test_with_time <- master_df6 %>% filter(Code %in% coun3)   #filtering a/c to code vector created above

head(Test_with_time)  #checking the result
```
Creating new columns to get the total infected, total tests and total tests per million and grouping the values by country to get rows having observations of the entire duration in 1 row

```{r}
test_country_detail <- Test_with_time %>%
  group_by(Country) %>%
  summarise(infected_total = max(CumCases), total_tests = max(CumTests), total_test_per_million = max(Tests_1M_Pop))

test_country_detail
```

```{r}
plot_covid_test <- test_country_detail %>% pivot_longer( #converting data to long format for creating grouped bar chart
  cols = c(infected_total, total_tests, total_test_per_million),  #naming new columns to test_detail
  names_to = "Test_Detail"
)
plot_covid_test #checking the result
```

```{r}
# plotting the data

p3 <- ggplot(plot_covid_test, aes(
  x = Country,
  y = value,
  col = Test_Detail,
  group = Test_Detail,
  fill = Test_Detail
)) +
  geom_bar(position = "dodge", stat = "identity") +
  # To set x axis labels as vertical
  theme(axis.text.x = element_text(
    angle = 90,
    hjust = 1,
    vjust = 0.5
  ))

# Format y axis tick mark labels to show exponents
require(scales)
p3 + scale_y_continuous(
  trans = log10_trans(),
  breaks = trans_breaks("log10", function(x) 10^x),
  labels = trans_format("log10", math_format(10^.x))
)
```
### 12.Build a graph to present the statistics of all continents which was obtained previously in question 8 (Use log for Y axis for better presentation, Use Continent in the legend, make sure x-axis labels does not overlap). 


```{r}
c_plot <- continent_data %>% pivot_longer( #converting data to long format for creating grouped bar chart
  cols = c(case_con, death_con, recov_con, test_con),  #naming new columns to Confirmed_Data
  names_to = "Confirmed_Data"
)
c_plot
```

```{r}
# plotting the data

# library(gghighlight)
p4 <- ggplot(c_plot, aes(
  x = Continent,
  y = value,
  col = Confirmed_Data,
  group = Continent,
  fill = Continent, alpha = 10
)) +
  geom_bar(stat = "identity", position = "dodge") +
  # To set x axis labels as vertical
  theme(axis.text.x = element_text(
    angle = 90,
    hjust = 1,
    vjust = 0.5
  ))

# Format y axis tick mark labels to show exponents
require(scales)
p4 + scale_y_continuous(
  trans = log10_trans(),
  breaks = trans_breaks("log10", function(x) 10^x),
  labels = trans_format("log10", math_format(10^.x))
)
```

# ------------------------------------------------------------------------------- #

## Task 3: Data-Driven Modelling: (14 marks)

### 1. Based on the data of the last day, that you have extracted in the previous task, create a separate dataframe named “cor_data” with the data of these variables (CumCases, CumTests, Population, GDP, GDPCapita).

[Hint: you can use select function on the lastday_data dataframe]

```{r}
library(tidyverse)
c_data <- lastDay_data %>% select(CumCases, CumTests, Population, GDP, GDPCapita) #using the select function to only keep the required columns
cor_data <- c_data[-1] #removing the first column with country names
cor_data
```
### 2. Compute the correlation matrix between the variables of the “cor_data” and visualise this correlation matrix
```{r}
cor(cor_data)
# show correlation matrix to check the correlation
# install.packages("GGally")
library(GGally)
ggcorr(cor_data, label = TRUE, label_alpha = TRUE)
```

```{r}
# show box plot to all of the variables to check the out-liers
meltData <- cor_data %>%
  gather()

p <- ggplot(meltData, aes(key, value))

p + geom_boxplot() + facet_wrap(~key, scale = "free") # viewing separately as the scale of the variables is different
```

### 3. visualise the distribution of the cumulative cases in the cor_data with and without changing the scale of the x axis to log transformation.

[Hint: you can use the geom_histrogram function]
```{r}
#plotting without changing scale of x-axis
ggplot(cor_data, aes(CumCases)) +
  geom_histogram(aes(y = ..count..), fill = "aquamarine3", bins = 50, position ='jitter', na.rm=TRUE) 
  
```
```{r}
ggplot(cor_data, aes(CumCases)) +
  geom_histogram(aes(y = ..density..), fill = "aquamarine3", bins = 50, position ='jitter', na.rm=TRUE) +
  scale_x_log10()
  
```
The distribution looks more evenly spread out when we take the log values of x-axis as compared to its original values.






### 4. Divide the cor_data into training and testing, where training data represent 65% of the number of rows.

```{r}
# split data into train and test
# install.packages("caret")
library(caret)

set.seed(2)
index <- createDataPartition(cor_data$CumCases, p = .65, list = FALSE)
length(cor_data$CumCases)

train <- cor_data[index, ]
test <- cor_data[-index, ]

dim(train)
dim(test)
```

### 5. Train a linear regression model to predict cumulative cases from the GDP of the countries. Then, evaluate this model on the test data and print the root mean square error value.

```{r}
# build a linear regression model only between cumulative cases and GDP of the countries
lmModel <- lm(CumCases ~ GDP, data = train)
print(lmModel)

# Validating Regression Coefficients and Models
summary(lmModel)

# visualise the model
plot(lmModel)
```


```{r}
# predicting
test$PredictedCumCases <- predict(lmModel, test)
head(test[, c("CumCases", "PredictedCumCases")])

# compute the residual mean square error (RMSE) as a way of evaluation
actual <- test$CumCases
preds <- test$PredictedCumCases
RMSE(preds, actual)
```


### 6.Train another linear regression model to predict cumulative cases from all the other variables. Then, evaluate this model on the test data and print the root mean square error value

```{r}
# build a linear model between the CumCases and all of the other variables
lmModel1 <- lm(CumCases ~ ., data = train)
print(lmModel1)

# Validating Regression Coefficients and Models
summary(lmModel1)
```





```{r}
# predicting
test$PredictedCumCases_1 <- predict(lmModel1, test)
head(test[, c("CumCases", "PredictedCumCases", "PredictedCumCases_1")])

# RMSE
actual <- test$CumCases
preds <- test$PredictedCumCases_1

RMSE(preds, actual)
```

### 7. Interpret the two models and write a small report of highlighting the differences between using the two models. For example, in which cases we should use the first model and in which cases the second one is better to use.

-  Linear regression is used to predict the value of a continuous variable Y based on one or more input predictor variables X. 
-  Here in above 2 cases the X variable is the cumulative cases(explanatory variable) and y is the predictor/response variable. 
-  The predictor variable can be 1 variable out of the data frame which means that the value of CumCases only depends on that one variable.


-  In the <b>first Linear Regression model</b> we built, we were assuming that the future value of cumulative cases only depended on the GDP of that country. According to our assumption: The Cumulative Cases and GDP have a linear relationship with each other and that is why we are selecting a linear regression model for prediction values. 
-  The Root Mean Square Error of 1st model was 76591.77. This is a very high value of error and proves that the model is inaccurate or the variables need to be changed into log values to extract a linear relationship.
-  The model 1 can be used in cases where we are sure that the Cumulative cases only depend on the GDP of that country and has no relationship/effect from the others.It can be used where limited information and only one response variable is available or where we are absolutely sure that the value of cumulative cases depends on only the GDP.The distribution of data points should be linear on the scatter plot.


-  In the <b>second Linear Regression model</b> we built, we were assuming that the future value of cumulative cases depended on all other variables such as the GDP of that country, GDP per capita, Population, Cumulative Tests of that country. According to our assumption: The Cumulative Cases and all other variables have a linear relationship with each other and that is why we are selecting a linear regression model. 
-  The Root Mean Square Error of 2nd model was 44927.77. This is a very high value of error and proves that the model is inaccurate or the variables need to be changed into log values to extract a linear relationship.
-  The model 2 is better than model 1 because it has comparatively less error. It can be used in cases where all the data is available and we have more variables that determine the future value of Cumulative Cases.



# ------------------------------------------------------------------------------- #

## Task 4: Insights (8 marks)

Imagine you have been asked to plan for a dashboard that shall show the trends and the main figures of the different Covid19 waves that happened world wide, so far. Given the current data in this assignment is only covering the first wave of the Covid19, how would you augment this data? What are the other sources of data that you will rely on? What types of figures will you be focusing on to show in your dashboard? and why?

Write the report as follows:

## Note: Please see attached dashboard image

## Aim:- To create a dashboard with augmented Covid-19 data to spread correct information about the pandemic.


## 1. Objectives:
  -  Obtain Realtime Covid-19 data from credible sources.
  -  Process the data to create meaningful and easy to understand charts/graphs
  -  Present key highlights about the pandemic total cases, deaths, recovered and tests count
  -  Create a section for precautions and set of do's and don't's for infected persons
  -  Create a Section for emergency contact numbers and services
  

## 2. List of data sources to augment the existing data:
  - John Hopkins University and Medicine data on Coronavirus resource center. http://coronavirus.jhu.edu
  - Centers for Disease Control and Prevention Covid-19 Data Sources: https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covid-19-data-sources.html
  - Australian Govt, Dept of Health and Aged Care: https://www.health.gov.au/health-alerts/covid-19/case-numbers-and-statistics
  - WHO COVID-19 Research Database: who.int/emergencies/diseases/novel-coronavirus-2019/global-research-on-novel-coronavirus-2019-ncov


## 3. Set of figures/tables to show in the dashboard:
  - Zoomable world map showing infected cases in each country(shinydashboard can  be done by using leaflet in R)
  - Side bar Panel with cases highlights showing numbers of infected cases, deaths, recovered and tests count
  - Graph on comparison of infected cases and deaths
  - Graph on comparison of number of total tests taken and the infected number of people
  - Graph on the fatality rate and recovery rate of each country
  - Table listing important contact information for each region
  - Table showing infographics on the set of do's and don't's to be followed by positive cases


## 4. Analysis strategy:

  - Process the data to create files which consistently are updated and appended with current day information
  - cross sectional analysis of covid-19 with other global pandemics such as Ebola,H1N1,etc
  - identify and display geographical location of covid-hotspots an nearest health centers
  - analysing the total number of tests and positive and negative cases to understand current trend and encourage tests and    vaccination
  - create Machine Learning models to predict future infected cases and their exponential increase.



# ----------------------------------------------------------------------------------------------------------- #
